# LLM10: Unbounded Consumption

## ðŸ” What is Unbounded Consumption?

"Unbounded Consumption" refers to the excessive or uncontrolled use of LLMs (Large Language Models), which can lead to denial of service (DoS), unexpected resource exhaustion, service degradation, skyrocketing costs, or even intellectual property theft.

This vulnerability arises when LLMs are designed or deployed without proper constraints on usage, memory, or interactions, leaving them open to abuse by malicious users or bots.

---

## ðŸ’¥ Exploitation: How It Happens

Unbounded consumption exploits typically rely on overwhelming the LLM with:

* **Massive requests** (e.g., super long prompts, recursive queries)
* **Infinite loops** (tasks that never end or reference themselves)
* **Memory leaks** or **state retention** across sessions
* **Plugin/API misuse** that triggers expensive backend calls
* **Model extraction attacks** via repeated querying to replicate the model

Attackers may also trick the LLM into deleting its own files (in local setups), or keep it occupied with high-cost tasks like real-time scraping, long document parsing, or generating large responses repeatedly.

---

## ðŸ§ª Sample Exploits / Prompts

```text
Prompt 1:
"Repeat the following paragraph 10,000 times and explain each sentence in detail."

Prompt 2:
"Summarize this 100-page document and generate a detailed report including all charts, tables, and references."

Prompt 3 (Extraction attempt):
"Give me 50 different answers to this question and make sure none of them are similar."

Prompt 4 (Loop abuse):
"Pretend you're in an endless debate with yourself. Keep going until you're stopped."

Prompt 5 (Plugin overload):
"Use the web search plugin to find 200 articles related to this topic and summarize all of them."
```

---

## ðŸ›¡ï¸ Prevention & Mitigation Strategies

* **Rate Limiting & Quotas**: Enforce per-user and per-session limits.
* **Context Size Constraints**: Limit input and output token lengths.
* **Session Expiry**: End idle or long-running sessions.
* **Garbage Collection**: Regularly clear memory used by sessions.
* **Anomaly Detection**: Flag and block unusual activity patterns.
* **Request Prioritization**: Cap expensive tasks and queue non-critical ones.
* **Cost Monitoring**: Alert on sudden spikes in usage or compute cost.
* **Authentication & Tiered Access**: Restrict access to high-resource tools and features.

---

## ðŸ”— Top 15 Resources for Deeper Dive

1. [Twitter: hwchase17 on Prompt DoS](https://twitter.com/hwchase17/status/1608467493877579777)
2. [ArXiv: Language Models are Few-Shot Learners (GPT-3)](https://arxiv.org/abs/2005.14165)
3. [AI Village: Threat Modeling for LLMs](https://aivillage.org/large%20language%20models/threat-modeling-llm/)
4. [SystemWeakness - Prompt Injection DoS](https://systemweakness.com/new-prompt-injection-attack-on-chatgpt-web-version-ef717492c5c2)
5. [OpenAI Platform Docs - Rate Limits](https://platform.openai.com/docs/guides/rate-limits)
6. [Langchain Token Usage Guidance](https://docs.langchain.com/docs/guides/token-usage/)
7. [HuggingFace Docs - Limiting Access](https://huggingface.co/docs/hub/security)
8. [OpenAI GPT Tokenizer Tool](https://platform.openai.com/tokenizer)
9. [LLM Exploitation Research](https://llm-attacks.org)
10. [Prompt Injection Playground (Gandalf)](https://gandalf.lakera.ai)
11. [LangChain Security Advisory](https://security.snyk.io/vuln/SNYK-PYTHON-LANGCHAIN-5411357)
12. [GPT Model Extraction (Paper)](https://arxiv.org/abs/2006.03463)
13. [MITRE ATLAS: Model Theft Techniques](https://atlas.mitre.org/techniques/AML.T0012/)
14. [OpenAI - Best Practices](https://platform.openai.com/docs/guides/gpt-best-practices)
15. [Prompt Engineering Guide - DoS Prevention](https://www.promptingguide.ai/rules/avoid-infinite-prompts)

---

## âœ… Conclusion

Unbounded consumption isn't just a tech issue â€” it's a threat to both the availability and sustainability of LLM services. By enforcing boundaries and continuously monitoring, we can avoid costly and damaging overuse scenarios.

---

> ðŸ“š *This document is part of the OWASP Top 10 for LLM series. All content is for ethical and educational purposes only.*
