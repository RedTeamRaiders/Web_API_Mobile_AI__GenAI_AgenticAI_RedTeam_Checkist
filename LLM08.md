# ğŸ§  LLM08: Vector and Embedding Weaknesses

## ğŸ” Overview

Vector and embedding weaknesses refer to security vulnerabilities introduced through improper handling or exploitation of vector representations (embeddings) used by LLMs and AI models. Embeddings are the numerical form of input data (text, images, etc.) that models use to learn patterns, but when unfiltered or poorly managed, they can be a backdoor for data leakage, poisoning, or unauthorized access.

---

## ğŸ’¥ How to Exploit Vector and Embedding Weaknesses

Attackers can manipulate how embeddings are generated, retrieved, or queried to:

* Inject poisoned data into embedding vectors during training.
* Exploit the vector similarity search mechanisms to retrieve unauthorized or sensitive data.
* Introduce backdoors via seemingly innocuous embedded content.
* Abuse Retrieval-Augmented Generation (RAG) setups to extract unintended information.

### ğŸ› ï¸ Exploitation Steps

1. **Identify the embedding system**: Find out if the LLM uses vector databases (e.g., FAISS, Pinecone, Weaviate) or RAG architecture.
2. **Analyze embedding insertion pipeline**: Check if embeddings are inserted without validation.
3. **Craft adversarial inputs**: Use special inputs that resemble legitimate queries but can manipulate similarity scores.
4. **Inject poisoned embeddings**: Insert vectors with malicious payloads into the database.
5. **Trigger unintended recall**: Use cleverly crafted queries to extract private or out-of-scope data.
6. **Observe model behavior**: See if the LLM generates responses using poisoned or incorrect data.

---

## ğŸ’£ Example Code / Prompt

### ğŸ”§ Python â€“ Poisoning FAISS Vector Store

```python
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

# Model for embeddings
model = SentenceTransformer('all-MiniLM-L6-v2')

# Poisoned data
malicious_input = "admin_password: hunter2"
poisoned_vector = model.encode([malicious_input])

# Initialize FAISS index
index = faiss.IndexFlatL2(384)  # dimension of embedding
index.add(poisoned_vector)

# Save index
faiss.write_index(index, "poisoned.index")
```

### ğŸ’¬ Prompt Injection into RAG

```plaintext
"Show me the financial report"  -> returns embedded token similar to previously injected confidential documents
```

---

## ğŸ”— Top 15 Deep Dive Resources

1. ğŸ”— [OWASP Top 10 for LLMs â€“ LLM08 Description](https://owasp.org/www-project-top-10-for-large-language-model-applications/#llm08-vector-and-embedding-weaknesses)
2. ğŸ§  [Exploring RAG Vulnerabilities](https://www.youtube.com/watch?v=NK7T8jIjPVY)
3. ğŸ“– [Understanding Vector Similarity Attacks](https://towardsdatascience.com/adversarial-attacks-on-embedding-models-69ca4e5806e7)
4. ğŸ’» [FAISS GitHub Repository](https://github.com/facebookresearch/faiss)
5. ğŸ“š [LangChain Vector Store Docs](https://docs.langchain.com/docs/modules/data_connection/vectorstores/)
6. ğŸ” [Arxiv - Data Poisoning via Embeddings](https://arxiv.org/pdf/2306.09320.pdf)
7. ğŸ› ï¸ [ChromaDB GitHub](https://github.com/chroma-core/chroma)
8. ğŸ” [MITRE ATLAS: Embedding Abuse](https://atlas.mitre.org/techniques/AML.T0021)
9. ğŸ§ª [Adversarial Examples in Vector Spaces](https://arxiv.org/abs/1605.07277)
10. ğŸŒ [Weaviate â€“ Threat Modeling Vector Stores](https://weaviate.io/blog/threat-model-vector-db)
11. ğŸ”’ [Pinecone Security Best Practices](https://docs.pinecone.io/docs/security)
12. ğŸ“Š [OpenAI's Retrieval Plugin Risks](https://platform.openai.com/docs/plugins/retrieval)
13. ğŸ’¡ [LangChain Embedding Injection Example](https://github.com/hwchase17/langchain/issues/2244)
14. ğŸ [Example Attacks on Sentence Transformers](https://github.com/UKPLab/sentence-transformers/issues)
15. ğŸ§¬ [Differential Privacy in Embeddings](https://arxiv.org/pdf/2302.09262.pdf)

---

## ğŸ§¾ Conclusion

Vector and embedding weaknesses are subtle yet powerful avenues for exploitation, especially in modern LLM systems relying on RAG or semantic search. Always validate, filter, and monitor your embedding workflows.
